http://people.eecs.berkeley.edu/~raluca/cs261-f15/readings/dwork.pdf

### 摘要

1977年，Dalenius希望建立一种统计数据库满足：不能从数据库中学习关于个人的任何知识，即如果不能访问数据库，就无法学习。（nothing about an individual should be learnable from the database that cannot be learned without access to the database.）这后来被证明无法实现，但证明同时发现我们甚至能够威胁到那些不在数据库中的人的隐私。于是提出了差分隐私这种测量，捕捉**参与数据库为一个个体的隐私泄露所带来的风险**。通过实现相关技术，我们能够实现不同程度的隐私，同时使数据库呈现出准确的信息。

### 1.简介

希望数据库能够在不泄露个体信息的同时，展示整体的代表性信息。

我们需要定义隐私：怎么算没能保护隐私？盗窃隐私的对手的能力有哪些？虽然不能访问数据库但对手有哪些辅助信息？

我们还需定义效能（utility），因为如果什么不发表或只发布噪声那肯定能保护隐私，但数据库本身没有意义。

论文中我们先讨论隐私，然后在满足一定隐私的条件下，讨论能达到哪些效能。
Dalenius想建立的理想的统计数据库被我们证明无法实现，实现的障碍在于对手有额外的信息。

语义安全（Semantic Security)在密码学中可以实现，但在数据库背景下不能实现，这是因为他们两者实现的效能（utility）是不同的。比如数据库无法区分使用者和对手，对手了解数据库的信息类型等。

本文中我们进行：1.语义安全在数据库背景下的不可能性证明 2.差分隐私的定义 3.将差分隐私用于实践。

### 2.隐私数据分析：设置（The setting）

隐私机制有两种模式：交互式和非交互式。非交互式设置将数据进行匿名化处理，然后发布“消毒后”的数据。交互式设置提供一个查询接口，发布查询结果（可能含噪音）。交互式下的隐私安全已被包括本文的一些文章中解决，非交互式下的隐私安全更难实现。（可能是因为在提供消毒数据时还不能确定这些数据需要满足的效能。）

### 3.Impossibility of Absolute Disclosure Prevention

### 4.Differential Privacy

无法保证数据库对于隐私的完全保护，我们提出差分隐私。这是一种保证，保证你的个人数据在或不在这个数据库里面，以及你做或不做任何事情，对于你个人隐私的泄露几乎没有影响。

差分隐私的原始定义：A randomized function K gives ε-differential privacy if for all
data sets D1 and D2 differing on at most one element, and all S ⊆ Range(K),
Pr[K(D1) ∈ S] ≤ exp(ε) × Pr[K(D2) ∈ S]

简单举例，一个保险公司查询一个符合差分隐私的数据库，来决定是否接受小明的投保。小明的数据（或者任何某人的数据）在或不在这个数据库里面，都不会明显影响保险公司的决定。

可将这个定义拓展到一个群体中，对于个体满足ε-差分隐私的机制，对于一个含有c个个体的群体，同样满足cε-差分隐私。cε会随着群体的大小c的增长而增长。

### 5.Achieving Differential Privacy

对于交互式机制，应该考虑结合先前查询的结果，当前查询是否会破坏机制的隐私性。

L1-sensitivity的定义:一个查询函数f对于任意相邻数据集，查询结果差的最大值△f。（详见文章的Difinition 3）。L1-sensitivity是一个查询函数的性质，与数据集无关。

一种机制Kf，Pr[Kf (X) = a] ∝ exp(−||f(X) − a||/σ)。则Kf满足 (∆f /σ)-差分隐私。
